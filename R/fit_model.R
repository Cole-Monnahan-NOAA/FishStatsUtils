
#' Fit VAST to data
#'
#' \code{fit_model} fits a spatio-temporal model to data
#'
#' This function is the user-interface for the multiple mid-level functions that
#' perform separate components of a spatio-temporal analysis:
#' \itemize{
#' \item determine the extrapolation-grid \code{\link{make_extrapolation_info}},
#' \item define spatial objects \code{\link{make_spatial_info}},
#' \item build covariates from a formula interface \code{\link{make_covariates}},
#' \item assemble data \code{\link{make_data}},
#' \item build model \code{\link{make_model}},
#' \item estimate parameters \code{\link[TMBhelper]{fit_tmb}}, and
#' \item check for obvious problems with the estimates \code{\link{check_fit}}.
#' }
#' Please see reference documetation for each of those functions (e.g., \code{?make_extrapolation_info}) to see a list of arguments used by each mid-level function.
#'
#' Specifically, the mid-level functions called by \code{fit_model(.)} look for arguments in the following order of precedence (from highest to lowest precedence):
#' \enumerate{
#' \item \code{fit_model(.)} prioritizes using named arguments passed directly to \code{fit_model(.)}. If arguments are passed this way, they are used instead of other options below.
#' \item If an argument is not passed supplied directly to \code{fit_model(.)}, then \code{fit_model(.)} looks for elements in input \code{settings}, as typically created by \code{\link{make_settings}}.
#' \item If an argument is not supplied via (1) or (2) above, then each mid-level function uses default values defined in those function arguments, e.g., see \code{args(make_extrapolation_info)} for defaults for function \code{make_extrapolation_info(.)}
#' }
#' Collectively, this order of precedence allows users to specify inputs for a specific project via input method (1), the package author to change defaults through changes in the settings
#' defined for a given purpose in \code{make_settings(.)} via input method (2), while still defaulting to package defaults via option (3).
#'
#' Variables are indexed internally for locations \code{g}, categories \code{c}, and times \code{y}.
#' Location index \code{g} represents Longitude-Latitude \code{fit$extrapolation_list$Data_Extrap[which(fit$spatial_list$g_e==g),c('Lon','Lat')]};
#' Time index \code{y} represents time \code{fit$year_labels}; and
#' Category \code{g} corresponds to values in \code{fit$data_list$g_i}.
#'
#' @inheritParams make_extrapolation_info
#' @inheritParams make_spatial_info
#' @inheritParams make_covariates
#' @inheritParams VAST::make_data
#' @inheritParams VAST::make_model
#' @inheritParams TMBhelper::fit_tmb
#' @param settings Output from \code{\link{make_settings}}
#' @param run_model Boolean indicating whether to run the model or simply return the inputs and built TMB object
#' @param test_fit Boolean indicating whether to apply \code{VAST::check_fit} before calculating standard errors, to test for parameters hitting bounds etc; defaults to TRUE
#' @param ... additional arguments to pass to \code{\link{make_extrapolation_info}}, \code{\link{make_spatial_info}}, \code{\link[VAST]{make_data}}, \code{\link[VAST]{make_model}}, or \code{\link[TMBhelper]{fit_tmb}},
#' where arguments are matched by name against each function.  If an argument doesn't match, it is still passed to \code{\link[VAST]{make_data}}.  Note that \code{\link{make_spatial_info}}
#' passes named arguments to \code{\link[INLA]{inla.mesh.create}}.
#'
#' @return Object of class \code{fit_model}, containing formatted inputs and outputs from VAST
#' \describe{
#'   \item{parameter_estimates}{Output from \code{\link[TMBhelper]{fit_tmb}}; see that documentation for definition of contents}
#'   \item{extrapolation_list}{Output from \code{\link{make_extrapolation_info}}; see that documentation for definition of contents}
#'   \item{spatial_list}{Output from \code{\link{make_spatial_info}}; see that documentation for definition of contents}
#'   \item{data_list}{Output from \code{\link[VAST]{make_data}}; see that documentation for definition of contents}
#'   \item{tmb_list}{Output from \code{\link[VAST]{make_model}}; see that documentation for definition of contents}
#'   \item{ParHat}{Tagged list of maximum likelihood estimatesion of fixed effects and empirical Bayes estimates of random effects, following format of initial values generated by \code{\link[VAST]{make_parameters}}; see that documentation for definition of contents}
#'   \item{Report}{Tagged list of VAST outputs. For example, estimated density for grid \code{g}, category \code{c}, and time \code{y} is available as \code{fit$Report$D_gcy[g,c,y]}; see Details section for description of indexing}
#' }
#'
#' @family wrapper functions
#' @seealso \code{\link[VAST]{VAST}} for general documentation, \code{\link[FishStatsUtils]{make_settings}} for generic settings, \code{\link[FishStatsUtils]{fit_model}} for model fitting, and \code{\link[FishStatsUtils]{plot_results}} for generic plots
#' @seealso \code{\link{summary.fit_model}} for methods to summarize output, including obtain a dataframe of estimated densities
#'
#' @examples
#' \dontrun{
#' # Load packages
#' library(TMB)
#' library(VAST)
#'
#' # load data set
#' # see `?load_example` for list of stocks with example data
#' # that are installed automatically with `FishStatsUtils`.
#' example = load_example( data_set="EBS_pollock" )
#'
#' # Make settings
#' settings = make_settings( n_x=50,
#'          Region=example$Region,
#'          purpose="index",
#'          strata.limits=example$strata.limits )
#'
#' # Run model
#' fit = fit_model( "settings"=settings,
#'     "Lat_i"=example$sampling_data[,'Lat'],
#'     "Lon_i"=example$sampling_data[,'Lon'],
#'     "t_i"=example$sampling_data[,'Year'],
#'     "c_i"=rep(0,nrow(example$sampling_data)),
#'     "b_i"=example$sampling_data[,'Catch_KG'],
#'     "a_i"=example$sampling_data[,'AreaSwept_km2'],
#'     "v_i"=example$sampling_data[,'Vessel'] )
#'
#' # Plot results
#' plot_results( settings=settings, fit=fit )
#' }
#'
#' @export
#' @md
# Using https://cran.r-project.org/web/packages/roxygen2/vignettes/rd-formatting.html for guidance on markdown-enabled documentation
fit_model = function( settings, Lat_i, Lon_i, t_i, b_i, a_i, c_iz=rep(0,length(b_i)),
  v_i=rep(0,length(b_i)), working_dir=paste0(getwd(),"/"),
  X1config_cp=NULL, X2config_cp=NULL, covariate_data, X1_formula=~0, X2_formula=~0,
  Q1config_k=NULL, Q2config_k=NULL, catchability_data, Q1_formula=~0, Q2_formula=~0,
  newtonsteps=1, silent=TRUE, build_model=TRUE, run_model=TRUE, test_fit=TRUE, ... ){

  # Capture extra arguments to function
  extra_args = list(...)
  # Backwards-compatible way to capture previous format to input extra arguments for each function via specific input-lists
  extra_args = c( extra_args, extra_args$extrapolation_args, extra_args$spatial_args, extra_args$optimize_args, extra_args$model_args )

  # Assemble inputs
  data_frame = data.frame( "Lat_i"=Lat_i, "Lon_i"=Lon_i, "a_i"=a_i, "v_i"=v_i, "b_i"=b_i, "t_i"=t_i, "c_iz"=c_iz )
  # Decide which years to plot
  year_labels = seq( min(t_i), max(t_i) )
  years_to_plot = which( year_labels %in% t_i )

  # Save record
  dir.create(working_dir, showWarnings=FALSE, recursive=TRUE)
  #save( settings, file=file.path(working_dir,"Record.RData"))
  capture.output( settings, file=file.path(working_dir,"settings.txt"))

  # Build extrapolation grid
  message("\n### Making extrapolation-grid")
  extrapolation_args_default = list(Region=settings$Region, strata.limits=settings$strata.limits, zone=settings$zone,
    max_cells=settings$max_cells)
  extrapolation_args_input = combine_lists( input=extra_args, default=extrapolation_args_default, args_to_use=formalArgs(make_extrapolation_info) )
  extrapolation_list = do.call( what=make_extrapolation_info, args=extrapolation_args_input )

  # Build information regarding spatial location and correlation
  message("\n### Making spatial information")
  spatial_args_default = list(grid_size_km=settings$grid_size_km, n_x=settings$n_x, Method=settings$Method, Lon_i=Lon_i, Lat_i=Lat_i,
    Extrapolation_List=extrapolation_list, DirPath=working_dir, Save_Results=TRUE, fine_scale=settings$fine_scale, knot_method=settings$knot_method)
  spatial_args_input = combine_lists( input=extra_args, default=spatial_args_default, args_to_use=c(formalArgs(make_spatial_info),formalArgs(INLA::inla.mesh.create)) )
  spatial_list = do.call( what=make_spatial_info, args=spatial_args_input )

  # Build data
  # Do *not* restrict inputs to formalArgs(make_data) because other potential inputs are still parsed by make_data for backwards compatibility
  message("\n### Making data object") # VAST::
  if(missing(covariate_data)) covariate_data = NULL
  if(missing(catchability_data)) catchability_data = NULL
  data_args_default = list("Version"=settings$Version, "FieldConfig"=settings$FieldConfig, "OverdispersionConfig"=settings$OverdispersionConfig,
    "RhoConfig"=settings$RhoConfig, "VamConfig"=settings$VamConfig, "ObsModel"=settings$ObsModel, "c_iz"=c_iz, "b_i"=b_i, "a_i"=a_i, "v_i"=v_i,
    "s_i"=spatial_list$knot_i-1, "t_i"=t_i, "spatial_list"=spatial_list, "Options"=settings$Options, "Aniso"=settings$use_anisotropy,
    "X1config_cp"=X1config_cp, "X2config_cp"=X2config_cp, "covariate_data"=covariate_data, "X1_formula"=X1_formula, "X2_formula"=X2_formula,
    "Q1config_k"=Q1config_k, "Q2config_k"=Q2config_k, "catchability_data"=catchability_data, "Q1_formula"=Q1_formula, "Q2_formula"=Q2_formula )
  data_args_input = combine_lists( input=extra_args, default=data_args_default )  # Do *not* use args_to_use
  data_list = do.call( what=make_data, args=data_args_input )
  #return(data_list) }

  # Build object
  message("\n### Making TMB object")
  model_args_default = list("TmbData"=data_list, "RunDir"=working_dir, "Version"=settings$Version,
    "RhoConfig"=settings$RhoConfig, "loc_x"=spatial_list$loc_x, "Method"=spatial_list$Method, "build_model"=build_model)
  model_args_input = combine_lists( input=extra_args, default=model_args_default, args_to_use=formalArgs(make_model) )
  tmb_list = do.call( what=make_model, args=model_args_input )

  # Run the model or optionally don't
  if( run_model==FALSE | build_model==FALSE ){
    # Build and output
    input_args = list( "extra_args"=extra_args, "extrapolation_args_input"=extrapolation_args_input,
      "model_args_input"=model_args_input, "spatial_args_input"=spatial_args_input,
      "data_args_input"=data_args_input )
    Return = list("data_frame"=data_frame, "extrapolation_list"=extrapolation_list, "spatial_list"=spatial_list,
      "data_list"=data_list, "tmb_list"=tmb_list, "year_labels"=year_labels, "years_to_plot"=years_to_plot,
      "settings"=settings, "input_args"=input_args)
    class(Return) = "fit_model"
    return(Return)
  }
  if(silent==TRUE) tmb_list$Obj$env$beSilent()

  # Check for obvious problems with model
  if( test_fit==TRUE ){
    message("\n### Testing model at initial values")
    LogLike0 = tmb_list$Obj$fn( tmb_list$Obj$par )
    Gradient0 = tmb_list$Obj$gr( tmb_list$Obj$par )
    if( any( Gradient0==0 ) ){
      message("\n")
      stop("Please check model structure; some parameter has a gradient of zero at starting values\n", call.=FALSE)
    }else{
      message("Looks good: All fixed effects have a nonzero gradient")
    }
  }

  # Optimize object
  message("\n### Estimating parameters")
  # have user override upper, lower, and loopnum
  optimize_args_default1 = combine_lists( default=list(lower=tmb_list$Lower, upper=tmb_list$Upper, loopnum=2),
    input=extra_args, args_to_use=formalArgs(TMBhelper::fit_tmb) )
  # auto-override user inputs for optimizer-related inputs for first test run
  optimize_args_input1 = list(obj=tmb_list$Obj, savedir=NULL, newtonsteps=0, bias.correct=FALSE,
    control=list(eval.max=10000,iter.max=10000,trace=1), quiet=TRUE, getsd=FALSE )
  # combine
  optimize_args_input1 = combine_lists( default=optimize_args_default1, input=optimize_args_input1, args_to_use=formalArgs(TMBhelper::fit_tmb) )
  parameter_estimates = do.call( what=TMBhelper::fit_tmb, args=optimize_args_input1 )

  # Check fit of model (i.e., evidence of non-convergence based on bounds, approaching zero, etc)
  if(exists("check_fit") & test_fit==TRUE ){
    problem_found = VAST::check_fit( parameter_estimates )
    if( problem_found==TRUE ){
      message("\n")
      stop("Please change model structure to avoid problems with parameter estimates and then re-try; see details in `?check_fit`\n", call.=FALSE)
    }
    #Report = tmb_list$Obj$report()
    #ParHat = tmb_list$Obj$env$parList( parameter_estimates$par )
    #Return = list("data_frame"=data_frame, "extrapolation_list"=extrapolation_list, "spatial_list"=spatial_list,
    #  "data_list"=data_list, "tmb_list"=tmb_list, "parameter_estimates"=parameter_estimates, "Report"=Report,
    #  "ParHat"=ParHat, "year_labels"=year_labels, "years_to_plot"=years_to_plot, "settings"=settings,
    #  "input_args"=input_args )
    #return( invisible(Return) )
  }

  # Restart estimates after checking parameters
  optimize_args_default2 = list(obj=tmb_list$Obj, lower=tmb_list$Lower, upper=tmb_list$Upper,
    savedir=working_dir, bias.correct=settings$bias.correct, newtonsteps=newtonsteps,
    bias.correct.control=list(sd=FALSE, split=NULL, nsplit=1, vars_to_correct=settings$vars_to_correct),
    control=list(eval.max=10000,iter.max=10000,trace=1), loopnum=1)
  # combine while over-riding defaults using user inputs
  optimize_args_input2 = combine_lists( input=extra_args, default=optimize_args_default2, args_to_use=formalArgs(TMBhelper::fit_tmb) )
  # over-ride inputs to start from previous MLE
  optimize_args_input2 = combine_lists( input=list(startpar=parameter_estimates$par), default=optimize_args_input2 )
  parameter_estimates = do.call( what=TMBhelper::fit_tmb, args=optimize_args_input2 )

  # Extract standard outputs
  Report = tmb_list$Obj$report()
  ParHat = tmb_list$Obj$env$parList( parameter_estimates$par )

  # Build and output
  input_args = list( "extra_args"=extra_args, "extrapolation_args_input"=extrapolation_args_input,
    "model_args_input"=model_args_input, "spatial_args_input"=spatial_args_input,
    "optimize_args_input1"=optimize_args_input1, "optimize_args_input2"=optimize_args_input2,
    "data_args_input"=data_args_input )
  Return = list("data_frame"=data_frame, "extrapolation_list"=extrapolation_list, "spatial_list"=spatial_list,
    "data_list"=data_list, "tmb_list"=tmb_list, "parameter_estimates"=parameter_estimates, "Report"=Report,
    "ParHat"=ParHat, "year_labels"=year_labels, "years_to_plot"=years_to_plot, "settings"=settings, "input_args"=input_args,
    "X1config_cp"=X1config_cp, "X2config_cp"=X2config_cp, "covariate_data"=covariate_data, "X1_formula"=X1_formula, "X2_formula"=X2_formula,
    "Q1config_k"=Q1config_k, "Q2config_k"=Q1config_k, "catchability_data"=catchability_data, "Q1_formula"=Q1_formula, "Q2_formula"=Q2_formula)
  class(Return) = "fit_model"
  return( Return )
}

#' Print parameter estimates and standard errors.
#'
#' @title Print parameter estimates
#' @param x Output from \code{\link{fit_model}}
#' @param ... Not used
#' @return NULL
#' @method print fit_model
#' @export
print.fit_model <- function(x, ...)
{
  cat("fit_model(.) result\n")
  if( "parameter_estimates" %in% names(x) ){
    print( x$parameter_estimates )
  }else{
    cat("`parameter_estimates` not available in `fit_model`\n")
  }
  invisible(x$parameter_estimates)
}

#' Print parameter estimates and standard errors.
#'
#' @title Print parameter estimates
#' @param fit Output from \code{\link{fit_model}}
#' @param what String specifying what elements of results to plot;  options include `extrapolation_grid`, `spatial_mesh`, and `results`
#' @param ... Arguments passed to \code{\link{plot_results}}
#' @return NULL
#' @method plot fit_model
#' @export
plot.fit_model <- function(x, what="results", ...)
{
  if(!is.character(what)) stop("Check `what` in `plot.fit_model`")

  ## Plot extrapolation-grid
  if( length(grep(what, "extrapolation_grid")) ){
    cat("\n### Running `plot.make_extrapolation_info`\n")
    plot( x$extrapolation_list )
    return(invisible(NULL))
  }

  ## Plot extrapolation-grid
  if( length(grep(what, c("spatial_info","inla_mesh"))) ){
    cat("\n### Running `plot.make_spatial_info`\n")
    plot( x$spatial_list )
    return(invisible(NULL))
  }

  # diagnostic plots
  if( length(grep(what, "results")) ){
    cat("\n### Running `plot_results`\n")
    ans = plot_results( x, ... )
    return(invisible(ans))
  }

  stop( "input `what` not matching available options" )
}

#' Extract summary of spatial estimates
#'
#' \code{summary.fit_model} extracts commonly used quantities derived from a fitted VAST model
#'
#' \code{summary.fit_model} faciliates common queries for model output including:
#' \itemize{
#' \item \code{what="density"} returns a tagged list containing element \code{Density_dataframe},
#' which lists the estimated density for every Latitude-Longitude-Year-Category combination
#' for every modelled location in the extrapolation-grid.
#' \item \code{what="residuals"} returns a DHARMa object containing PIT residuals;
#' See details section for more information.
#' }
#'
#' For calculating residuals, the function calls package \code{\link[DHARMa]{DHARMa}}
#' to create a diagnostic object for simulation-based quantile residuals.
#' It specifically simulates replicated data sets from the predictive distribution of data
#' conditional on estimated fixed and random effects. It then
#' calculates probability-integral-transform (PIT) residuals from the observed and simulated values.
#' It then replaces the automatically calculated residuals in the DHARMa object with these these PIT residuals,
#' so that DHARMa can be used to plot those PIT residuals. PIT residuals are used because the original DHARMa calculations
#' are not correct when using a delta-model (due to additional jittered values added by DHARMa when detecting multiple 0-valued observations), hence
#' the need to call this function to correctly calculate PIT residuals for a delta-model.
#'
#' @inheritParams simulate_data
#'
#' @param x Output from \code{\link{fit_model}}
#' @param what String indicating what to summarize; options are `density` or `residuals`
#' @param n_samples Number of samples used when \code{what="residuals"}
#' @param ... additional arguments passed to \code{\link[DHARMa]{plotResiduals}} when \code{what="residuals"}
#'
#' @return NULL
#' @method summary fit_model
#' @export
summary.fit_model <- function(x, what="density", n_samples=250,
  working_dir=NULL, type=1, ...)
{
  ans = NULL

  if( tolower(what) == "density" ){
    # Load location of extrapolation-grid
    ans[["extrapolation_grid"]] = print( x$extrapolation_list, quiet=TRUE )

    # Load density estimates
    if( "D_gcy" %in% names(x$Report)){
      ans[["Density_array"]] =  x$Report$D_gcy
      if( !( x$settings$fine_scale==TRUE | x$spatial_list$Method=="Stream_network" ) ){
        index_tmp = x$spatial_list$NN_Extrap$nn.idx[ which(x$extrapolation_list[["Area_km2_x"]]>0), 1 ]
        ans[["Density_array"]] = ans[["Density_array"]][ index_tmp,,,drop=FALSE]
      }
      dimnames(ans[["Density_array"]]) = list( rownames(ans[["extrapolation_grid"]]), paste0("Category_",1:dim(ans[["Density_array"]])[[2]]), x$year_labels )
      # Expand as grid
      Density_dataframe = expand.grid("Grid"=1:dim(ans[["Density_array"]])[[1]], "Category"=dimnames(ans[["Density_array"]])[[2]], "Year"=dimnames(ans[["Density_array"]])[[3]])
      Density_dataframe = cbind( Density_dataframe, ans[["extrapolation_grid"]][Density_dataframe[,'Grid'],], "Density"=as.vector(ans[["Density_array"]]) )
      ans[["Density_dataframe"]] = Density_dataframe
      rownames(Density_dataframe) = NULL
      cat("\n### Printing head of and tail `Density_dataframe`, and returning data frame in output object")
      print(head(Density_dataframe))
      print(tail(Density_dataframe))
    }else{
      stop( "`summary.fit_model` not implemented for the version of `VAST` being used" )
    }
  }

  # Residuals
  if( tolower(what) == "residuals" ){
    # extract objects
    Obj = x$tmb_list$Obj
    Obj$env$data$n_g = 0

    # check for issues
    if( !(type %in% c(1,4)) ){
      warning("`type` only makes sense for 1 (measurement error) or 4 (unconditional) simulations")
    }

    b_iz = matrix(NA, nrow=length(x$data_list$b_i), ncol=n_samples)
    message( "Sampling from the distribution of data conditional on estimated fixed and random effects" )
    for( zI in 1:n_samples ){
      if( zI%%max(1,floor(n_samples/10)) == 0 ){
        message( "  Finished sample ", zI, " of ",n_samples )
      }
      b_iz[,zI] = simulate_data( fit=list(tmb_list=list(Obj=Obj)), type=type )$b_i
    }
    if( any(is.na(b_iz)) ){
      stop("Check simulated residuals for NA values")
    }

    # Run DHARMa
    dharmaRes = DHARMa::createDHARMa(simulatedResponse=b_iz, # + 1e-10*array(rnorm(prod(dim(b_iz))),dim=dim(b_iz)),
      observedResponse=x$data_list$b_i,
      integer=FALSE)

    # Calculate probability-integral-transform (PIT) residuals
    message( "Substituting probability-integral-transform (PIT) residuals for DHARMa-calculated residuals" )
    prop_lessthan_i = apply( b_iz<outer(x$data_list$b_i,rep(1,n_samples)), MARGIN=1, FUN=mean )
    prop_lessthanorequalto_i = apply( b_iz<=outer(x$data_list$b_i,rep(1,n_samples)), MARGIN=1, FUN=mean )
    # c( "Proportion_PIT_randomized"=mean(abs(prop_lessthan_i-prop_lessthanorequalto_i)>0.00001), "Proportion_zero"=mean(x$data_list$b_i==0) )
    PIT_i = runif(min=prop_lessthan_i, max=prop_lessthanorequalto_i, n=length(prop_lessthan_i) )
    # cbind( "Difference"=dharmaRes$scaledResiduals - PIT_i, "PIT"=PIT_i, "Original"=dharmaRes$scaledResiduals, "b_i"=x$data_list$b_i )
    dharmaRes$scaledResiduals = PIT_i

    # do plot
    if( is.null(working_dir) ){
      plot(dharmaRes, ...)
    }else if(!is.na(working_dir) ){
      png(file=paste0(working_dir,"quantile_residuals.png"), width=8, height=4, res=200, units='in')
        plot(dharmaRes, ...)
      dev.off()
    }

    # Return stuff
    ans = dharmaRes
    message( "Invisibly returning output from `DHARMa::createDHARMa`, e.g., to apply `plot.DHARMa` to this output")
  }

  if( tolower(what) %in% c("parhat","estimates") ){
    ans[["estimates"]] = x$ParHat
    cat("\n### Printing slots of `ParHat`, and returning list in output object")
    print(names(x$ParHat))
  }

  if( is.null(ans) ){
    stop( "`summary.fit_model` not implemented for inputted value of argument `what`" )
  }

  # diagnostic plots
  return(invisible(ans))
}


#' Predict density for new samples (\emph{Beta version; may change without notice})
#'
#' \code{predict.fit_model} calculates predictions given new data
#'
#' When the user does not supply \code{covariate_data}, predictions are based upon covariate values
#' interpolated from covariates supplied when fitting the model.  When the user does supply \code{covariate_data},
#' predictions are created when interpolating based on those new supplied values.
#'
#' @inheritParams make_covariates
#' @inheritParams VAST::make_data
#' @param x Output from \code{\link{fit_model}}
#' @param what Which output from \code{fit$Report} should be extracted; default is predicted density
#'
#' @return NULL
#' @method predict fit_model
#' @export
predict.fit_model <- function(x, what="D_i", Lat_i, Lon_i, t_i, a_i, c_iz=rep(0,length(t_i)),
  v_i=rep(0,length(t_i)), covariate_data=NULL, catchability_data=NULL,
  working_dir=paste0(getwd(),"/"))
{
  warning("`predict.fit_model(.)` is still in development")

  # Process inputs
  PredTF_i = c( x$data_list$PredTF_i, rep(1,length(t_i)) )
  b_i = c( x$data_frame[,"b_i"], rep(1,length(t_i)) )
  c_iz = rbind( matrix(x$data_frame[,grep("c_iz",names(x$data_frame))]), matrix(c_iz) )
  Lat_i = c( x$data_frame[,"Lat_i"], Lat_i )
  Lon_i = c( x$data_frame[,"Lon_i"], Lon_i )
  a_i = c( x$data_frame[,"a_i"], a_i )
  v_i = c( x$data_frame[,"v_i"], v_i )
  t_i = c( x$data_frame[,"t_i"], t_i )
  catchability_data = rbind( x$catchability_data, catchability_data )
  assign("b_i", b_i, envir=.GlobalEnv)

  # Populate covariate_data
  # Default: use original covariate values
  # When user provides new values, deal with missing years in covariate_data so that it doesn't throw an unnecessary error
  if( is.null(covariate_data) ){
    message("Using `covariate_data` supplied during original fit to interpolate covariate values for predictions")
    covariate_data = x$covariate_data
  }else{
    if( !(all(t_i %in% covariate_data[,'Year']) | any(is.na(covariate_data[,'Year']))) ){
      stop("Some `t_i` values are supplied without covariates")
    }else{
      message("Covariates not provided for all modeled years, so filling in zeros for covariates in other years")
      zeros_data = covariate_data[match(covariate_data[,'Year'],unique(covariate_data[,'Year'])),]
      zeros_data[,setdiff(names(zeros_data),c('Lat','Lon','Year'))] = 0
      zeros_data[,c('Lat','Lon')] = Inf
      covariate_data = rbind( covariate_data, zeros_data)
    }
  }

  # Build information regarding spatial location and correlation
  message("\n### Re-making spatial information")
  spatial_args_new = list("anisotropic_mesh"=x$spatial_list$MeshList$anisotropic_mesh, "Kmeans"=x$spatial_list$Kmeans,
    "Lon_i"=Lon_i, "Lat_i"=Lat_i )
  spatial_args_input = combine_lists( input=spatial_args_new, default=x$input_args$spatial_args_input )
  spatial_list = do.call( what=make_spatial_info, args=spatial_args_input )

  # Build data
  # Do *not* restrict inputs to formalArgs(make_data) because other potential inputs are still parsed by make_data for backwards compatibility
  message("\n### Re-making data object")
  data_args_new = list( "c_iz"=c_iz, "b_i"=b_i, "a_i"=a_i, "v_i"=v_i, "PredTF_i"=PredTF_i,
    "t_i"=t_i, "spatial_list"=spatial_list,
    "covariate_data"=covariate_data, "catchability_data"=catchability_data )
  data_args_input = combine_lists( input=data_args_new, default=x$input_args$data_args_input )  # Do *not* use args_to_use
  data_list = do.call( what=make_data, args=data_args_input )
  data_list$n_g = 0

  # Build object
  message("\n### Re-making TMB object")
  model_args_default = list("TmbData"=data_list, "RunDir"=working_dir, "Version"=x$settings$Version,
    "RhoConfig"=x$settings$RhoConfig, "loc_x"=spatial_list$loc_x, "Method"=spatial_list$Method)
  model_args_input = combine_lists( input=list("Parameters"=x$ParHat),
    default=model_args_default, args_to_use=formalArgs(make_model) )
  tmb_list = do.call( what=make_model, args=model_args_input )

  # Extract output
  Report = tmb_list$Obj$report()
  Y_i = Report[[what]][(1+nrow(x$data_frame)):length(Report$D_i)]

  # sanity check
  if( all.equal(covariate_data,x$covariate_data) & Report$jnll!=x$Report$jnll){
    message("Problem detected in `predict.fit_model`; returning outputs for diagnostic purposes")
    Return = list("Report"=Report, "data_list"=data_list)
    return(Return)
  }

  # return prediction
  return(Y_i)
}

